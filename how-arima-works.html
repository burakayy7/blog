<!DOCTYPE html>
<html>
<head>

    <!-- Document Settings -->
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />

    <!-- Base Meta -->
    <!-- dynamically fixing the title for tag/author pages -->



    <title>Part 2 - Implementing a Full ARIMA model from SCRATCH!</title>
    <meta name="HandheldFriendly" content="True" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <!-- Styles'n'Scripts -->
    <link rel="stylesheet" type="text/css" href="/blog/assets/built/screen.css" />
    <link rel="stylesheet" type="text/css" href="/blog/assets/built/screen.edited.css" />
    <link rel="stylesheet" type="text/css" href="/blog/assets/built/syntax.css" />
    <!-- highlight.js -->
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css">
    <style>.hljs { background: none; }</style>

    <!--[if IE]>
        <style>
            p, ol, ul{
                width: 100%;
            }
            blockquote{
                width: 100%;
            }
        </style>
    <![endif]-->
    
    <!-- This tag outputs SEO meta+structured data and other important settings -->
    <meta name="description" content="My Blog for Technical Projects" />
    <link rel="shortcut icon" href="https://burakayy.com/blog/assets/images/favicon.png" type="image/png" />
    <link rel="canonical" href="https://burakayy.com/blog/how-arima-works" />
    <meta name="referrer" content="no-referrer-when-downgrade" />

     <!--title below is coming from _includes/dynamic_title-->
    <meta property="og:site_name" content="Burak Ayyorgun" />
    <meta property="og:type" content="website" />
    <meta property="og:title" content="Part 2 - Implementing a Full ARIMA model from SCRATCH!" />
    <meta property="og:description" content="Here, we will build off the last lesson and properly implement an Autoregressive, Integrated, Moving Average Model. As usual, I will be using the same data as in the previous lesson. The fundamental change this time, is that we will have NumPy, an open-source numerical computation Python tool, handle all" />
    <meta property="og:url" content="https://burakayy.com/blog/how-arima-works" />
    <meta property="og:image" content="https://burakayy.com/blog/assets/images/AutoCorr/predictions7.png" />
    <meta property="article:publisher" content="https://www.facebook.com/ghost" />
    <meta property="article:author" content="https://www.facebook.com/ghost" />
    <meta property="article:published_time" content="2024-03-15T00:00:00+00:00" />
    <meta property="article:modified_time" content="2024-03-15T00:00:00+00:00" />
    <meta property="article:tag" content="Arima" />
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="Part 2 - Implementing a Full ARIMA model from SCRATCH!" />
    <meta name="twitter:description" content="Here, we will build off the last lesson and properly implement an Autoregressive, Integrated, Moving Average Model. As usual, I will be using the same data as in the previous lesson. The fundamental change this time, is that we will have NumPy, an open-source numerical computation Python tool, handle all" />
    <meta name="twitter:url" content="https://burakayy.com/blog/" />
    <meta name="twitter:image" content="https://burakayy.com/blog/assets/images/AutoCorr/predictions7.png" />
    <meta name="twitter:label1" content="Written by" />
    <meta name="twitter:data1" content="Burak Ayyorgun" />
    <meta name="twitter:label2" content="Filed under" />
    <meta name="twitter:data2" content="Arima" />
    <meta name="twitter:site" content="@JoeBA07" />
    <meta name="twitter:creator" content="@JoeBA07" />
    <meta property="og:image:width" content="1400" />
    <meta property="og:image:height" content="933" />

    <script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Website",
    "publisher": {
        "@type": "Organization",
        "name": "Burak Ayyorgun",
        "logo": "https://burakayy.com/blog/Burak Ayyorgun"
    },
    "url": "https://burakayy.com/blog/how-arima-works",
    "image": {
        "@type": "ImageObject",
        "url": "https://burakayy.com/blog/assets/images/AutoCorr/predictions7.png",
        "width": 2000,
        "height": 666
    },
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "https://burakayy.com/blog/how-arima-works"
    },
    "description": "Here, we will build off the last lesson and properly implement an Autoregressive, Integrated, Moving Average Model. As usual, I will be using the same data as in the previous lesson. The fundamental change this time, is that we will have NumPy, an open-source numerical computation Python tool, handle all"
}
    </script>

    <!-- <script type="text/javascript" src="https://demo.ghost.io/public/ghost-sdk.min.js?v=724281a32e"></script>
    <script type="text/javascript">
    ghost.init({
    	clientId: "ghost-frontend",
    	clientSecret: "f84a07a72b17"
    });
    </script> -->

    <meta name="generator" content="Jekyll 3.6.2" />
    <link rel="alternate" type="application/rss+xml" title="Part 2 - Implementing a Full ARIMA model from SCRATCH!" href="/blog/feed.xml" />


</head>
<body class="post-template">

    <div class="site-wrapper">
        <!-- All the main content gets inserted here, index.hbs, post.hbs, etc -->
        <!-- default -->
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
<!-- The tag above means: insert everything in this file
into the {body} of the default.hbs template -->

<header class="site-header outer">
    <div class="inner">
        
<nav class="site-nav">
    <div class="site-nav-left">
        
            
                <!-- <a class="site-nav-logo" href="https://burakayy.com/blog/"><img src="/blog/Burak Ayyorgun" alt="Burak Ayyorgun" /></a> -->
            <!-- <a class="site-nav-logo" href="https://burakayy.com/blog/">Home</a> -->
            
        
        
            <ul class="nav" role="menu">
    <li class="nav-home" role="menuitem" style="font-size: 20px; opacity: 0.99;"><a href="/blog/">Home</a></li>
    <li class="nav-about" role="menuitem" style="font-size: 20px; opacity: 0.99;"><a href="/blog/about/">About</a></li>
    <li class="nav-about" role="menuitem" style="font-size: 20px; opacity: 0.99;"><a href="/blog/courses">Courses</a></li>
    <!-- <li class="nav-getting-started" role="menuitem"><a href="/blog/tag/getting-started/">Getting Started</a></li> -->
    <!-- <li class="nav-try-ghost" role="menuitem"><a href="https://ghost.org">Try Ghost</a></li> -->
</ul>

        
    </div>
    <div class="site-nav-right">
        <!-- New navigation link -->
        <ul class="nav" role="menu">
            <li class="nav-home" role="menuitem" style="font-size: 20px; opacity: 1;"><a href="/blog/miscellaneous">Old Miscellaneous Projects</a></li>
        </ul>


        <!-- Social media links -->
        <div class="social-links">
            
                <a class="social-link social-link-fb" href="https://facebook.com/ghost" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path d="M19 6h5V0h-5c-3.86 0-7 3.14-7 7v3H8v6h4v16h6V16h5l1-6h-6V7c0-.542.458-1 1-1z"/></svg>
</a>
            
            
                <a class="social-link social-link-tw" href="https://twitter.com/JoeBA07" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path d="M30.063 7.313c-.813 1.125-1.75 2.125-2.875 2.938v.75c0 1.563-.188 3.125-.688 4.625a15.088 15.088 0 0 1-2.063 4.438c-.875 1.438-2 2.688-3.25 3.813a15.015 15.015 0 0 1-4.625 2.563c-1.813.688-3.75 1-5.75 1-3.25 0-6.188-.875-8.875-2.625.438.063.875.125 1.375.125 2.688 0 5.063-.875 7.188-2.5-1.25 0-2.375-.375-3.375-1.125s-1.688-1.688-2.063-2.875c.438.063.813.125 1.125.125.5 0 1-.063 1.5-.25-1.313-.25-2.438-.938-3.313-1.938a5.673 5.673 0 0 1-1.313-3.688v-.063c.813.438 1.688.688 2.625.688a5.228 5.228 0 0 1-1.875-2c-.5-.875-.688-1.813-.688-2.75 0-1.063.25-2.063.75-2.938 1.438 1.75 3.188 3.188 5.25 4.25s4.313 1.688 6.688 1.813a5.579 5.579 0 0 1 1.5-5.438c1.125-1.125 2.5-1.688 4.125-1.688s3.063.625 4.188 1.813a11.48 11.48 0 0 0 3.688-1.375c-.438 1.375-1.313 2.438-2.563 3.188 1.125-.125 2.188-.438 3.313-.875z"/></svg>
</a>
            
        </div>
        
            <a class="subscribe-button" href="#subscribe">Subscribe</a>
        
    </div>
</nav>

    </div>
</header>

<!-- Everything inside the #post tags pulls data from the post -->
<!-- #post -->

<main id="site-main" class="site-main outer" role="main">
    <div class="inner">

        <article class="post-full  tag-arima post ">

            <header class="post-full-header">
                <section class="post-full-meta">
                    <time class="post-full-meta-date" datetime="15 March 2024">15 March 2024</time>
                    
                        <span class="date-divider">/</span>
                        
                            
                               <a href='/blog/tag/arima/'>ARIMA</a>
                            
                        
                    
                </section>
                <h1 class="post-full-title">Part 2 - Implementing a Full ARIMA model from SCRATCH!</h1>
            </header>

            
            <figure class="post-full-image" style="background-image: url(/blog/assets/images/AutoCorr/predictions7.png); height: 400px; background-size: cover; background-position: center;">
            </figure>
            

            <section class="post-full-content" style="margin-top: 60px;">
                <div class="kg-card-markdown">
                    <p>Here, we will build off the last lesson and properly implement an Autoregressive, Integrated, Moving Average Model.</p>

<p>As usual, I will be using the same data as in the previous lesson.</p>

<p>The fundamental change this time, is that we will have <a href="https://numpy.org/">NumPy</a>, an open-source numerical computation Python tool, handle all of these
multiplications for us.</p>

<p>I believe that when running this algorithm, the problem would occur:
\(\frac{\partial \text{MSE}}{\partial b_i} = \frac{2}{n} \cdot \sum_{i=p}^n x_{t-i} \cdot (x_{t-p}\cdot b_{t-p} +\ldots +x_{t-i}\cdot b_{t-i} - y_t)\)</p>

<p>Previously, we relied solely on Python arithmetic for this, but there is also an alternative method: <strong>The Dot Product!</strong></p>

\[\beta = (X^T \cdot X)^{-1} \cdot X^T \cdot y\]

\[\beta = X^{+} \cdot y\]

<p>The above is a super simplified version of something called the <a href="https://en.wikipedia.org/wiki/Moore%E2%80%93Penrose_inverse">Moore-Penrose Inverse</a>. It is somewhat technical, so I decided to keep that out of this lesson.</p>

<h3 id="the-code">The Code</h3>

<p>To keep this simple, I will first show you the new code:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">math</span>
<span class="k">def</span> <span class="nf">prepare_data</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">order</span><span class="p">):</span>
  <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">order</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)):</span>
    <span class="n">X</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span> <span class="o">-</span> <span class="n">order</span><span class="p">:</span><span class="n">i</span><span class="p">])</span>
    <span class="n">y</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
  <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">prepare_data_errors</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">order</span><span class="p">):</span>
  <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">order</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)):</span>
    <span class="n">X</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">errors</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span> <span class="o">-</span> <span class="n">order</span><span class="p">:</span><span class="n">i</span><span class="p">])</span>
    <span class="n">y</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">y</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
  <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">autoregressive_model</span> <span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">order</span><span class="p">,</span> <span class="n">cost</span><span class="p">):</span>
  <span class="c1">#prepare data
</span>  <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">prepare_data</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">order</span><span class="p">)</span>
  <span class="c1">#weights = np.random.randn(order)
</span>  <span class="n">weights</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">order</span><span class="p">)]</span>
  <span class="n">bias</span> <span class="o">=</span> <span class="mi">0</span>

  <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epoch</span><span class="p">):</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>
    <span class="n">error</span> <span class="o">=</span> <span class="n">predictions</span> <span class="o">-</span> <span class="n">y</span>

    <span class="k">if</span> <span class="n">cost</span> <span class="o">==</span> <span class="s">'mse'</span><span class="p">:</span>
      <span class="n">gradient_weights</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="n">T</span><span class="p">,</span> <span class="n">error</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
      <span class="n">gradient_bias</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">error</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">cost</span> <span class="o">==</span> <span class="s">'mae'</span><span class="p">:</span>
      <span class="c1">#print(error/np.abs(error))
</span>      <span class="n">gradient_weights</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="n">T</span><span class="p">,</span> <span class="n">error</span><span class="o">/</span><span class="n">np</span><span class="p">.</span><span class="nb">abs</span><span class="p">(</span><span class="n">error</span><span class="p">))</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
      <span class="n">gradient_bias</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">error</span><span class="o">/</span><span class="n">np</span><span class="p">.</span><span class="nb">abs</span><span class="p">(</span><span class="n">error</span><span class="p">))</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">cost</span> <span class="o">==</span> <span class="s">'rmse'</span><span class="p">:</span>
      <span class="n">gradient_weights</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="n">T</span><span class="p">,</span> <span class="n">error</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">))</span> <span class="o">/</span> <span class="mi">2</span> <span class="o">/</span> <span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">square</span><span class="p">(</span><span class="n">error</span><span class="p">))</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
      <span class="c1">#gradient_bias = np.sum(error) / len(X) / np.sqrt(sum(error))
</span>      <span class="n">gradient_bias</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">error</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">square</span><span class="p">(</span><span class="n">error</span><span class="p">))</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>



    <span class="n">weights</span> <span class="o">-=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">gradient_weights</span>
    <span class="c1">#bias -= learning_rate * gradient_bias
</span>
  <span class="k">return</span> <span class="n">weights</span><span class="p">,</span> <span class="n">bias</span>
</code></pre></div></div>
<p>As you can see, it looks pretty similar to the previous function. However, each arithmetic operation (like calculating the error or running the gradient descent algorithm) is handled with NumPy:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epoch</span><span class="p">):</span>
  <span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>
  <span class="n">error</span> <span class="o">=</span> <span class="n">predictions</span> <span class="o">-</span> <span class="n">y</span>
</code></pre></div></div>

<h4 id="the-dot-product-simplified">The Dot Product, Simplified</h4>
<p>If you don’t know how a dot product works, please review this resource <a href="https://www.mathsisfun.com/algebra/vectors-dot-product.html">here</a>.</p>

<p>But if I were to explain it in simple terms, I would say that it is a method to finding the product of two vectors in space. When I say that, you might think to multiply their lengths, but this is false as it doesn’t account for vectors that face different directions. Thus, there is a super simple method (which I will not explain right now; if you want, please view the source above) that looks like this for taking the dot product:</p>

\[let \vec{b} = \begin{bmatrix}b_1 \\ b_2 \\ \vdots \\ b_i\end{bmatrix}\]

<p>and 
\(let \vec{X} = \begin{bmatrix}x_1 \\ x_2 \\ \vdots \\ x_i\end{bmatrix}\)</p>

<p>Then, their dot product will be:
\(\vec{b} \cdot \vec{X} = (b_1 \cdot x_1 + b_2 \cdot x_2 + \ldots + b_i \cdot x_i)\)</p>

<p>And you might be able to see, that this is actually the same operation we do when we calculate our error in the autoregressive function:
\((x_{t-p}\cdot b_{t-p} +\ldots +x_{t-i}\cdot b_{t-i})\)</p>

<p>Thus, we can run our Gradient Descent algorithm with NumPy dot product operations; this way, we can allow NumPy to handle all of the arithmetic operations, which was causing an issue in our previous try.</p>

<p>I also put in the calculations for all of the other cost functions we will be looking at in this lesson, but we will discuss those later.
Furthermore, the below line is specifically when we update the weights (they are treated as an array of weights, for simplicity):</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="n">weights</span> <span class="o">-=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">gradient_weights</span>
</code></pre></div></div>

<p>Anyways, if you run the above code in succession with this:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_size</span> <span class="o">=</span> <span class="p">.</span><span class="mi">5</span>
<span class="n">used_data</span> <span class="o">=</span> <span class="n">data</span>
<span class="n">used_data</span><span class="p">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s">'y'</span><span class="p">]</span>
<span class="n">train</span> <span class="o">=</span> <span class="n">used_data</span><span class="p">[:</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">used_data</span><span class="p">)</span><span class="o">*</span><span class="n">train_size</span><span class="p">)]</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">used_data</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">used_data</span><span class="p">)</span><span class="o">*</span><span class="n">train_size</span><span class="p">):]</span>
<span class="n">train</span><span class="p">.</span><span class="n">plot</span><span class="p">()</span>
<span class="n">test</span><span class="p">.</span><span class="n">plot</span><span class="p">()</span>
<span class="n">beta</span><span class="p">,</span> <span class="n">bias</span> <span class="o">=</span> <span class="n">autoregressive_model</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="s">'mse'</span><span class="p">)</span>
<span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">prepare_data</span><span class="p">(</span><span class="n">test</span><span class="p">,</span> <span class="mi">12</span><span class="p">)</span>
<span class="n">x_plot</span><span class="p">,</span> <span class="n">y_plot</span> <span class="o">=</span> <span class="n">prepare_data</span><span class="p">(</span><span class="n">test</span><span class="p">,</span> <span class="mi">12</span><span class="p">)</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span><span class="o">+</span><span class="n">bias</span>
<span class="n">pred</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s">'Predictions'</span><span class="p">])</span>
<span class="n">actual</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">y_plot</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s">'actual'</span><span class="p">])</span>
<span class="n">actual</span><span class="p">.</span><span class="n">plot</span><span class="p">()</span>
<span class="n">pred</span><span class="p">.</span><span class="n">plot</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>
<p>You should get graphs like these:
<img src="assets/images/AutoCorr/predictions6.png" alt="i" />
<img src="assets/images/AutoCorr/graph5.png" alt="m" />
<img src="assets/images/AutoCorr/graph6.png" alt="g" /></p>

<p>And as you can see, our predictions look very similar to our actual values. 
We DID it!!!</p>

<p>We made our own autoregressive model!! Now all we have to do is implement this and a moving average model together in the ARIMA.</p>

<p>So, the only thing we changed from the last lesson is how we dealt with the arithmetic operation, but fundamentally they are the same.</p>

<h2 id="implementing-a-moving-average-model">Implementing a Moving Average Model</h2>

<p>As you have probably heard what a Moving Average Model is, from the previous lessons, it is basically like an autoregressive model, but by taking the average.</p>

<p>A moving average model is a regression against past errors (from the autoregressive function). Mathematically, it looks like this:</p>

\[y_t = c + \theta_1 \cdot \mathcal{E}_{t-1} + \theta_2 \cdot \mathcal{E}_{t-2} + \ldots + \theta_q \cdot \mathcal{E}_{t-q} \tag{1}\]

<p>Where <em>c</em> is the mean of the series, and <em>q</em> is the order/lag amount.</p>

<p>In theory, any MA(q) can be represented as AR(p), this is known as invertibility. <a href="https://otexts.com/fpp2/arima-r.html#plotting-the-characteristic-roots">There is some really nice math behind this that I would really like to dive into; however, I am afraid it might be out of scope, so I might touch on it briefly at the end</a>.</p>

<p>Below is my autoregressive, moving average model:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">moving_average_model</span><span class="p">(</span><span class="n">errors</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">order</span><span class="p">,</span> <span class="n">cost</span><span class="p">):</span>
  <span class="c1">#prepare data
</span>  <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">order</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">errors</span><span class="p">)):</span>
    <span class="n">X</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span> <span class="o">-</span> <span class="n">order</span><span class="p">:</span><span class="n">i</span><span class="p">])</span>
    <span class="n">y</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
  <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
  <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
  <span class="c1">#weights = np.random.randn(order)
</span>  <span class="n">theta</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">order</span><span class="p">)]</span>
  <span class="n">bias</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">y</span><span class="p">:</span>
    <span class="n">bias</span> <span class="o">+=</span> <span class="n">i</span>
  <span class="n">bias</span> <span class="o">=</span> <span class="p">(</span><span class="n">bias</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

  <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epoch</span><span class="p">):</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">theta</span><span class="p">)</span>
    <span class="n">error</span> <span class="o">=</span> <span class="n">predictions</span> <span class="o">-</span> <span class="n">y</span>

    <span class="k">if</span> <span class="n">cost</span> <span class="o">==</span> <span class="s">'mse'</span><span class="p">:</span>
      <span class="n">gradient_weights</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="n">T</span><span class="p">,</span> <span class="n">error</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
      <span class="n">gradient_bias</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">error</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">cost</span> <span class="o">==</span> <span class="s">'mae'</span><span class="p">:</span>
      <span class="n">gradient_weights</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="n">T</span><span class="p">,</span> <span class="n">error</span><span class="o">/</span><span class="n">np</span><span class="p">.</span><span class="nb">abs</span><span class="p">(</span><span class="n">error</span><span class="p">))</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
      <span class="n">gradient_bias</span> <span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">error</span><span class="o">/</span><span class="n">np</span><span class="p">.</span><span class="nb">abs</span><span class="p">(</span><span class="n">error</span><span class="p">))</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">cost</span> <span class="o">==</span> <span class="s">'rmse'</span><span class="p">:</span>
      <span class="n">gradient_weights</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="n">T</span><span class="p">,</span> <span class="n">error</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">))</span> <span class="o">/</span> <span class="mi">2</span> <span class="o">/</span> <span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">square</span><span class="p">(</span><span class="n">error</span><span class="p">))</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
      <span class="n">gradient_bias</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">error</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

    <span class="n">theta</span> <span class="o">-=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">gradient_weights</span>
    <span class="c1">#bias -= learning_rate * gradient_bias
</span>
  <span class="k">return</span> <span class="n">theta</span><span class="p">,</span> <span class="n">bias</span>
</code></pre></div></div>

<p>This is very, very similar to the autoregressive function. I will leave the above function to the reader to figure out (I view this as a nice exercise to allow the reader to be more engaged and in-tune to what is being said).</p>

<h2 id="finally-the-arima-model">Finally, the ARIMA Model</h2>

<p>Below, is part of the code for implementing the ARIMA model, it is dependent on the previous two functions we discussed:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">reverse_stationary_fn</span><span class="p">(</span><span class="n">ori_x</span><span class="p">,</span> <span class="n">new_x</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">new_x</span><span class="p">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">x</span> <span class="o">+=</span> <span class="n">ori_x</span><span class="p">.</span><span class="n">shift</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">+=</span> <span class="n">ori_x</span><span class="p">.</span><span class="n">diff</span><span class="p">().</span><span class="n">shift</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span>
<span class="k">def</span> <span class="nf">un_difference_data</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
  <span class="n">new_data</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">copy</span><span class="p">()</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)):</span>
    <span class="n">new_data</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">+</span><span class="n">data</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
  <span class="k">return</span> <span class="n">new_data</span>
<span class="k">def</span> <span class="nf">squared_error</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">actual</span><span class="p">):</span>
  <span class="n">error</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">pred</span><span class="p">)):</span>
    <span class="c1">#print(pred.iloc[i].item())
</span>    <span class="n">error</span> <span class="o">+=</span> <span class="p">(</span><span class="n">actual</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">-</span><span class="n">pred</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">item</span><span class="p">())</span><span class="o">**</span><span class="mi">2</span>
  <span class="k">return</span> <span class="n">error</span>
<span class="k">def</span> <span class="nf">first_and_last</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
  <span class="n">new_data</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)):</span>
    <span class="n">new_data</span><span class="p">.</span><span class="n">append</span><span class="p">((</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">11</span><span class="p">]))</span>
  <span class="k">return</span> <span class="n">new_data</span>

<span class="k">def</span> <span class="nf">arima</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">train_size</span><span class="p">,</span> <span class="n">cost_function</span><span class="p">):</span>
  <span class="n">train_ori</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">*</span><span class="n">train_size</span><span class="p">)]</span>
  <span class="n">test_ori</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">*</span><span class="n">train_size</span><span class="p">):]</span>

  <span class="n">stationary</span> <span class="o">=</span> <span class="n">difference_data</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
  <span class="c1">#stationary = data
</span>  <span class="n">train</span> <span class="o">=</span> <span class="n">stationary</span><span class="p">[:</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">stationary</span><span class="p">)</span><span class="o">*</span><span class="n">train_size</span><span class="p">)]</span>
  <span class="n">test</span> <span class="o">=</span> <span class="n">stationary</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">stationary</span><span class="p">)</span><span class="o">*</span><span class="n">train_size</span><span class="p">):]</span>

  <span class="c1">#prepare data
</span>  <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">prepare_data</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>
  <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">prepare_data</span><span class="p">(</span><span class="n">test</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>
  <span class="n">start</span> <span class="o">=</span> <span class="n">test</span><span class="p">.</span><span class="n">index</span><span class="p">[</span><span class="mi">12</span><span class="p">]</span>

  <span class="n">beta</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">theta</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">ar_pred</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">ma_pred</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">train_pred</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epoch</span><span class="p">):</span>
    <span class="c1">#beta, bias = autoregressive_model(train, 0.001, 1, p)
</span>    <span class="c1">#ar_predictions = np.dot(X_train, beta)+bias
</span>    <span class="n">beta</span><span class="p">,</span> <span class="n">bias</span> <span class="o">=</span> <span class="n">autoregressive_model</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mi">300</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">cost_function</span><span class="p">)</span>
    <span class="n">ar_pred</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span><span class="o">+</span><span class="n">bias</span>
    <span class="n">train_pred</span> <span class="o">=</span> <span class="n">ar_pred</span>
    <span class="n">errors</span> <span class="o">=</span> <span class="n">ar_pred</span> <span class="o">-</span> <span class="n">y_train</span>
    <span class="n">df_errors</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="p">{</span><span class="s">'errors'</span><span class="p">:</span> <span class="n">errors</span><span class="p">,</span> <span class="s">'y'</span><span class="p">:</span> <span class="n">y_train</span><span class="p">})</span>

    <span class="n">theta</span><span class="p">,</span> <span class="n">mean</span> <span class="o">=</span> <span class="n">moving_average_model</span><span class="p">(</span><span class="n">df_errors</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">cost_function</span><span class="p">)</span>
    <span class="n">x_errors</span><span class="p">,</span> <span class="n">y_errors</span> <span class="o">=</span> <span class="n">prepare_data_errors</span><span class="p">(</span><span class="n">df_errors</span><span class="p">,</span> <span class="n">q</span><span class="p">)</span>
</code></pre></div></div>

<p>Let’s walk through it together. So first, in the ARIMA function, we split our data into training and testing, make that data stationary (this is the Integrating part of ARIMA, please refer to prior lessons), and we use a prepare_data function to output our data in a specific format (where they are in batches):</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_ori</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">*</span><span class="n">train_size</span><span class="p">)]</span>
<span class="n">test_ori</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">*</span><span class="n">train_size</span><span class="p">):]</span>

<span class="n">stationary</span> <span class="o">=</span> <span class="n">difference_data</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="c1">#stationary = data
</span><span class="n">train</span> <span class="o">=</span> <span class="n">stationary</span><span class="p">[:</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">stationary</span><span class="p">)</span><span class="o">*</span><span class="n">train_size</span><span class="p">)]</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">stationary</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">stationary</span><span class="p">)</span><span class="o">*</span><span class="n">train_size</span><span class="p">):]</span>

<span class="c1">#prepare data
</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">prepare_data</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>
<span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">prepare_data</span><span class="p">(</span><span class="n">test</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>
</code></pre></div></div>

<p>We start at 12 (because that is our order for this dataset; ideally I should of not of have hard coded this!) and create our weights and predictions arrays.</p>

<p>Next, in every epoch (pronounced e-po-ck; I learned this a bit too late!) we train an autoregressive model, get it’s predictions and the prediction errors, and then feed these <em>residuals</em> into our moving average model (by first converting it to the right format, like a Pandas DataFrame):</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epoch</span><span class="p">):</span>
  <span class="c1">#beta, bias = autoregressive_model(train, 0.001, 1, p)
</span>  <span class="c1">#ar_predictions = np.dot(X_train, beta)+bias
</span>  <span class="n">beta</span><span class="p">,</span> <span class="n">bias</span> <span class="o">=</span> <span class="n">autoregressive_model</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mi">300</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">cost_function</span><span class="p">)</span>
  <span class="n">ar_pred</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span><span class="o">+</span><span class="n">bias</span>
  <span class="n">train_pred</span> <span class="o">=</span> <span class="n">ar_pred</span>
  <span class="n">errors</span> <span class="o">=</span> <span class="n">ar_pred</span> <span class="o">-</span> <span class="n">y_train</span>
  <span class="n">df_errors</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="p">{</span><span class="s">'errors'</span><span class="p">:</span> <span class="n">errors</span><span class="p">,</span> <span class="s">'y'</span><span class="p">:</span> <span class="n">y_train</span><span class="p">})</span>

  <span class="n">theta</span><span class="p">,</span> <span class="n">mean</span> <span class="o">=</span> <span class="n">moving_average_model</span><span class="p">(</span><span class="n">df_errors</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">cost_function</span><span class="p">)</span>
  <span class="n">x_errors</span><span class="p">,</span> <span class="n">y_errors</span> <span class="o">=</span> <span class="n">prepare_data_errors</span><span class="p">(</span><span class="n">df_errors</span><span class="p">,</span> <span class="n">q</span><span class="p">)</span>

  <span class="c1"># BELOW: GET THE PREDICTIONS
</span>
  <span class="n">ar_predictions</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span><span class="o">+</span><span class="n">bias</span> <span class="c1">#FOR FULL
</span>  <span class="n">test_errors</span> <span class="o">=</span> <span class="n">ar_predictions</span> <span class="o">-</span> <span class="n">y_test</span>
  <span class="n">df_test_errors</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="p">{</span><span class="s">'errors'</span><span class="p">:</span> <span class="n">test_errors</span><span class="p">,</span> <span class="s">'y'</span><span class="p">:</span> <span class="n">y_test</span><span class="p">})</span>
  <span class="n">x_test_errors</span><span class="p">,</span> <span class="n">y_test_errors</span> <span class="o">=</span> <span class="n">prepare_data_errors</span><span class="p">(</span><span class="n">df_test_errors</span><span class="p">,</span> <span class="n">q</span><span class="p">)</span>
  <span class="n">ma_predictions</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x_test_errors</span><span class="p">,</span> <span class="n">theta</span><span class="p">)</span><span class="c1">#+mean
</span>
  <span class="c1"># BELOW: COMBINE THESE TO GET ARIMA PREDICTIONS
</span>
  <span class="n">pred</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ma_predictions</span><span class="p">)):</span>
    <span class="n">pred</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">ar_predictions</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">+</span><span class="n">ma_predictions</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
  <span class="n">pred</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span>
  <span class="n">data_range</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">date_range</span><span class="p">(</span><span class="n">start</span><span class="o">=</span><span class="n">start</span><span class="p">,</span> <span class="n">periods</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">pred</span><span class="p">),</span> <span class="n">freq</span><span class="o">=</span><span class="s">'M'</span><span class="p">)</span>
  <span class="n">data_range</span> <span class="o">=</span> <span class="n">test</span><span class="p">.</span><span class="n">index</span><span class="p">[</span><span class="mi">13</span><span class="p">:]</span>
  <span class="n">pred</span><span class="p">.</span><span class="n">set_index</span><span class="p">(</span><span class="n">data_range</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
  <span class="c1">#return un_difference_data(train), test_ori, un_difference_data(pred)
</span>  <span class="c1">#train_pred = pd.DataFrame(train_pred)
</span>  <span class="k">return</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span><span class="p">,</span> <span class="n">pred</span>
</code></pre></div></div>

<p>With the current AR and MA predictions, we add them up to the the ARIMA predictions.</p>

<p>Finally, we do some formatting on this final dataset, and <strong>Voila</strong>! A full ARIMA model coded from SCRATCH!!</p>

<p>(If you want, play around with all of the hyperparameters, like epoch size, the order, or  everything here: autoregressive_model(train, 0.2, 300, p, cost_function)).</p>

<p>Next up, I wanted compare the performance of various Cost functions, just for funzzies!</p>

<h3 id="cost-functions">Cost Functions</h3>

<p>There are many different cost functions out there, and each one can either help or hinder different models. In this lesson, I will show three main and common cost functions
<em>Mean Squared Error</em>(MSE), <em>Mean Absolute Error</em>(MAE), and <em>Root Mean Squared Error</em>(RMSE).</p>

<p>I have already coded in each cost function and their partial derivatives (I highly suggest you go through the math yourself on these, if you need any help, just reach out), so all we have to do is compare them here:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">training</span><span class="p">,</span> <span class="n">test</span><span class="p">,</span> <span class="n">predictions_mse</span> <span class="o">=</span> <span class="n">arima</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">q</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">epoch</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">train_size</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">cost_function</span><span class="o">=</span><span class="s">'mse'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"MSE squared error: "</span><span class="p">,</span> <span class="n">squared_error</span><span class="p">(</span><span class="n">predictions_mse</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>
<span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">training</span><span class="p">,</span> <span class="n">test</span><span class="p">,</span> <span class="n">predictions_mae</span> <span class="o">=</span> <span class="n">arima</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">q</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">epoch</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">train_size</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">cost_function</span><span class="o">=</span><span class="s">'mae'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"MAE squared error: "</span><span class="p">,</span> <span class="n">squared_error</span><span class="p">(</span><span class="n">predictions_mae</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>
<span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">training</span><span class="p">,</span> <span class="n">test</span><span class="p">,</span> <span class="n">predictions_rmse</span> <span class="o">=</span> <span class="n">arima</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">q</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">epoch</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">train_size</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">cost_function</span><span class="o">=</span><span class="s">'rmse'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"RMSE squared error: "</span><span class="p">,</span> <span class="n">squared_error</span><span class="p">(</span><span class="n">predictions_rmse</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>

</code></pre></div></div>

<p>And below, we plot them:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ax1=training.plot()
test.plot()
ax2 = predictions_mse.plot()
predictions_mae.plot(ax=ax2)
predictions_rmse.plot(ax=ax2)
</code></pre></div></div>

<p>Which should result in this:
<img src="assets/images/AutoCorr/graph7.png" alt="im" /></p>

<p>Above, is the data in stationary form.</p>

<p><img src="assets/images/AutoCorr/predictions7.png" alt="img" /></p>

<p>And as you can see, they all seem very similar. But if you looked at the print statements:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">MSE</span> <span class="n">squared</span> <span class="n">error</span><span class="p">:</span>  <span class="mf">1.0386990408088193</span>
<span class="n">MAE</span> <span class="n">squared</span> <span class="n">error</span><span class="p">:</span>  <span class="mf">0.9324816705511001</span>
<span class="n">RMSE</span> <span class="n">squared</span> <span class="n">error</span><span class="p">:</span>  <span class="mf">0.8846827347232624</span>
</code></pre></div></div>

<p>We see that <em>RMSE</em> had the least error.</p>

<p>Now, one thing I left out is turning this data make to non-stationary data. Since this lesson is already getting long, I would like to leave this up to the reader!</p>


                </div>
            </section>

            <!-- Email subscribe form at the bottom of the page -->
            
                <section class="subscribe-form">
                    <h3 class="subscribe-form-title">Subscribe to Burak Ayyorgun</h3>
                    <p>Get the latest posts delivered right to your inbox</p>
                    <form method="post" action="/subscribe/" class="">
    <input class="confirm" type="hidden" name="confirm"  /><input class="location" type="hidden" name="location"  /><input class="referrer" type="hidden" name="referrer"  />

    <div class="form-group">
        <input class="subscribe-email" type="email" name="email"  placeholder="youremail@example.com" />
    </div>
    <button class="" type="submit" disabled><span>Subscribe</span></button>
    <script type="text/javascript">(function(g,h,o,s,t){h[o]('.location')[s]=h[o]('.location')[s] || g.location.href;h[o]('.referrer')[s]=h[o]('.referrer')[s] || h.referrer;})(window,document,'querySelector','value');</script>
</form>

                </section>
            

            <footer class="post-full-footer">
                <!-- Everything inside the #author tags pulls data from the author -->
                <!-- #author-->
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                <!-- /author  -->
            </footer>

            <!-- If you use Disqus comments, just uncomment this block.
            The only thing you need to change is "test-apkdzgmqhj" - which
            should be replaced with your own Disqus site-id. -->
            

        </article>

    </div>
</main>

<!-- Links to Previous/Next posts -->
<aside class="read-next outer">
    <div class="inner">
        <div class="read-next-feed">
            
                
                
                
                
                    <article class="read-next-card"
                        
                            style="background-image: url(/blog/assets/images/planeBkg.jpg)"
                        
                    >
                        <header class="read-next-card-header">
                            <small class="read-next-card-header-sitetitle">&mdash; Burak Ayyorgun &mdash;</small>
                            
                                <h3 class="read-next-card-header-title"><a href="/blog/tag/arima/">Arima</a></h3>
                            
                        </header>
                        <div class="read-next-divider"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 14.5s2 3 5 3 5.5-2.463 5.5-5.5S21 6.5 18 6.5c-5 0-7 11-12 11C2.962 17.5.5 15.037.5 12S3 6.5 6 6.5s4.5 3.5 4.5 3.5"/></svg>
</div>
                        <div class="read-next-card-content">
                            <ul>
                                
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                    
                                        
                                        
                                            <li><a href="/blog/arima-future">Future Works & Next Steps</a></li>
                                        
                                    
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                    
                                  
                                
                                  
                                    
                                        
                                        
                                            <li><a href="/blog/arima-work">Part 1 - What are ARIMA models and how do they work?</a></li>
                                        
                                    
                                  
                                
                                  
                                    
                                        
                                        
                                            <li><a href="/blog/arima-library">Using Scikit & SKtime for Forecasting</a></li>
                                        
                                    
                                  
                                
                                  
                                    
                                        
                                        
                                    
                                  
                                
                                  
                                    
                                        
                                        
                                    
                                  
                                
                                  
                                    
                                        
                                        
                                    
                                  
                                
                                  
                                    
                                        
                                        
                                    
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                            </ul>
                        </div>
                        <footer class="read-next-card-footer">
                            <a href="/blog/tag/arima/">
                                
                                    See all 7 posts  →
                                
                            </a>
                        </footer>
                    </article>
                
            

            <!-- If there's a next post, display it using the same markup included from - partials/post-card.hbs -->
            
                

    <article class="post-card post-template">
        
            <a class="post-card-image-link" href="/blog/How-to-start-Arduino">
                <div class="post-card-image" style="background-image: url(/blog/assets/images/arduinoEng/arduino_getting_started.png)"></div>
            </a>
        
        <div class="post-card-content">
            <a class="post-card-content-link" href="/blog/How-to-start-Arduino">
                <header class="post-card-header">
                    
                        
                            
                                <span class="post-card-tags">Arduino</span>
                            
                        
                    

                    <h2 class="post-card-title">How to get started with Engineering</h2>
                </header>
                <section class="post-card-excerpt">
                    
                        <p>Hi, my name is Burak Ayyorgun and I wanted to share how I started with Engineering and give advice how you guys might want to start. The main goal is to find what</p>
                    
                </section>
            </a>
            <footer class="post-card-meta">
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                <span class="reading-time">
                    
                    
                      4 min read
                    
                </span>
            </footer>
        </div>
    </article>

            

            <!-- If there's a previous post, display it using the same markup included from - partials/post-card.hbs -->
            
                

    <article class="post-card post-template">
        
            <a class="post-card-image-link" href="/blog/arima-work">
                <div class="post-card-image" style="background-image: url(/blog/assets/images/AutoCorr/predictions5.png)"></div>
            </a>
        
        <div class="post-card-content">
            <a class="post-card-content-link" href="/blog/arima-work">
                <header class="post-card-header">
                    
                        
                            
                                <span class="post-card-tags">Arima</span>
                            
                        
                    

                    <h2 class="post-card-title">Part 1 - What are ARIMA models and how do they work?</h2>
                </header>
                <section class="post-card-excerpt">
                    
                        <p>Here, we will learn what ARIMA models are, how they work, and how they can be useful; we will also implement an Autoregressive model from SCRATCH!

</p>
                    
                </section>
            </a>
            <footer class="post-card-meta">
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                <span class="reading-time">
                    
                    
                      6 min read
                    
                </span>
            </footer>
        </div>
    </article>

            

        </div>
    </div>
</aside>

<!-- Floating header which appears on-scroll, included from includes/floating-header.hbs -->
<div class="floating-header">
    <div class="floating-header-logo">
        <a href="https://burakayy.com/blog/">
            
                <img src="/blog/assets/images/favicon.png" alt="Burak Ayyorgun icon" />
            
            <span>Burak Ayyorgun</span>
        </a>
    </div>
    <span class="floating-header-divider">&mdash;</span>
    <div class="floating-header-title">
        Part 2 - Implementing a Full ARIMA model from SCRATCH!
    <span></span></div>
    
    <div class="floating-header-share">
        <div class="floating-header-share-label">Share this <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
    <path d="M7.5 15.5V4a1.5 1.5 0 1 1 3 0v4.5h2a1 1 0 0 1 1 1h2a1 1 0 0 1 1 1H18a1.5 1.5 0 0 1 1.5 1.5v3.099c0 .929-.13 1.854-.385 2.748L17.5 23.5h-9c-1.5-2-5.417-8.673-5.417-8.673a1.2 1.2 0 0 1 1.76-1.605L7.5 15.5zm6-6v2m-3-3.5v3.5m6-1v2"/>
</svg>
</div>
        <a class="floating-header-share-tw" href="https://twitter.com/share?text=Part+2+-+Implementing+a+Full+ARIMA+model+from+SCRATCH%21&amp;url=https://burakayy.com/blog/how-arima-works"
            onclick="window.open(this.href, 'share-twitter', 'width=550,height=235');return false;">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path d="M30.063 7.313c-.813 1.125-1.75 2.125-2.875 2.938v.75c0 1.563-.188 3.125-.688 4.625a15.088 15.088 0 0 1-2.063 4.438c-.875 1.438-2 2.688-3.25 3.813a15.015 15.015 0 0 1-4.625 2.563c-1.813.688-3.75 1-5.75 1-3.25 0-6.188-.875-8.875-2.625.438.063.875.125 1.375.125 2.688 0 5.063-.875 7.188-2.5-1.25 0-2.375-.375-3.375-1.125s-1.688-1.688-2.063-2.875c.438.063.813.125 1.125.125.5 0 1-.063 1.5-.25-1.313-.25-2.438-.938-3.313-1.938a5.673 5.673 0 0 1-1.313-3.688v-.063c.813.438 1.688.688 2.625.688a5.228 5.228 0 0 1-1.875-2c-.5-.875-.688-1.813-.688-2.75 0-1.063.25-2.063.75-2.938 1.438 1.75 3.188 3.188 5.25 4.25s4.313 1.688 6.688 1.813a5.579 5.579 0 0 1 1.5-5.438c1.125-1.125 2.5-1.688 4.125-1.688s3.063.625 4.188 1.813a11.48 11.48 0 0 0 3.688-1.375c-.438 1.375-1.313 2.438-2.563 3.188 1.125-.125 2.188-.438 3.313-.875z"/></svg>

        </a>
        <a class="floating-header-share-fb" href="https://www.facebook.com/sharer/sharer.php?u=https://burakayy.com/blog/how-arima-works"
            onclick="window.open(this.href, 'share-facebook','width=580,height=296');return false;">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path d="M19 6h5V0h-5c-3.86 0-7 3.14-7 7v3H8v6h4v16h6V16h5l1-6h-6V7c0-.542.458-1 1-1z"/></svg>

        </a>
    </div>
    <progress class="progress" value="0">
        <div class="progress-container">
            <span class="progress-bar"></span>
        </div>
    </progress>
</div>


<!-- /post -->

<!-- The #contentFor helper here will send everything inside it up to the matching #block helper found in default.hbs -->







        <!-- Previous/next page links - displayed on every page -->
        

        <!-- The footer at the very bottom of the screen -->
        <footer class="site-footer outer">
            <div class="site-footer-content inner">
                <section class="copyright"><a href="https://burakayy.com/blog/">Burak Ayyorgun</a> &copy; 2026</section>
                <!-- <section class="poweredby">Proudly published with <a href="https://jekyllrb.com/">Jekyll</a> &
                    <a href="https://pages.github.com/" target="_blank" rel="noopener">GitHub Pages</a> using
                    <a href="https://github.com/jekyllt/jasper2" target="_blank" rel="noopener">Jasper2</a></section> -->
                <nav class="site-footer-nav">
                    <a href="/blog/">Latest Posts</a>
                    <a href="https://facebook.com/ghost" target="_blank" rel="noopener">Facebook</a>
                    <a href="https://twitter.com/JoeBA07" target="_blank" rel="noopener">Twitter</a>
                    <a href="https://ghost.org" target="_blank" rel="noopener">Ghost</a>
                </nav>
            </div>
        </footer>

    </div>

    <!-- The big email subscribe modal content -->
    
        <div id="subscribe" class="subscribe-overlay">
            <a class="subscribe-overlay-close" href="#"></a>
            <div class="subscribe-overlay-content">
                
                    <img class="subscribe-overlay-logo" src="/blog/Burak Ayyorgun" alt="Burak Ayyorgun" />
                
                <h1 class="subscribe-overlay-title">Subscribe to Burak Ayyorgun</h1>
                <p class="subscribe-overlay-description">Stay up to date! Get all the latest &amp; greatest posts delivered straight to your inbox</p>
                <form method="post" action="/subscribe/" class="">
    <input class="confirm" type="hidden" name="confirm"  /><input class="location" type="hidden" name="location"  /><input class="referrer" type="hidden" name="referrer"  />

    <div class="form-group">
        <input class="subscribe-email" type="email" name="email"  placeholder="youremail@example.com" />
    </div>
    <button class="" type="submit" disabled><span>Subscribe</span></button>
    <script type="text/javascript">(function(g,h,o,s,t){h[o]('.location')[s]=h[o]('.location')[s] || g.location.href;h[o]('.referrer')[s]=h[o]('.referrer')[s] || h.referrer;})(window,document,'querySelector','value');</script>
</form>

            </div>
        </div>
    

    <!-- highlight.js -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.10.0/components/prism-abap.min.js"></script>
    <script>$(document).ready(function() {
      $('pre code').each(function(i, block) {
        hljs.highlightBlock(block);
      });
    });</script>

    <!-- Load the core Prism.js library -->
<!--     <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.10.0/prism.min.js"></script>
    
    <!-- Load the ABAP language component for Prism.js -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.10.0/components/prism-abap.min.js"></script>
    
    <!-- Initialize Prism.js (no need for extra jQuery or highlight.js) -->
    <script>$(document).ready(function() {
      $('pre code').each(function(i, block) {
        hljs.highlightBlock(block);
      });
    });</script>
    <script>
      document.addEventListener('DOMContentLoaded', (event) => {
        // Prism.js will automatically highlight all <code> blocks on the page
      });
    </script> -->


    <!-- jQuery + Fitvids, which makes all video embeds responsive -->
    <script
        src="https://code.jquery.com/jquery-3.2.1.min.js"
        integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4="
        crossorigin="anonymous">
    </script>
    <script type="text/javascript" src="/blog/assets/js/jquery.fitvids.js"></script>
    <script type="text/javascript" src="https://demo.ghost.io/assets/js/jquery.fitvids.js?v=724281a32e"></script>


    <!-- Paginator increased to "infinit" in _config.yml -->
    <!-- if paginator.posts  -->
    <!-- <script>
        var maxPages = parseInt('');
    </script>
    <script src="/blog/assets/js/infinitescroll.js"></script> -->
    <!-- /endif -->

    


    <!-- Add Google Analytics  -->
    <!-- Google Analytics Tracking code -->
 <!-- <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'G-MY3WXBS5JD', 'auto');
  ga('send', 'pageview');

 </script> -->

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-MY3WXBS5JD"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-MY3WXBS5JD');
</script>


    <!-- The #block helper will pull in data from the #contentFor other template files. In this case, there's some JavaScript which we only want to use in post.hbs, but it needs to be included down here, after jQuery has already loaded. -->
    
        <script>

// NOTE: Scroll performance is poor in Safari
// - this appears to be due to the events firing much more slowly in Safari.
//   Dropping the scroll event and using only a raf loop results in smoother
//   scrolling but continuous processing even when not scrolling
$(document).ready(function () {
    // Start fitVids
    var $postContent = $(".post-full-content");
    $postContent.fitVids();
    // End fitVids

    var progressBar = document.querySelector('progress');
    var header = document.querySelector('.floating-header');
    var title = document.querySelector('.post-full-title');

    var lastScrollY = window.scrollY;
    var lastWindowHeight = window.innerHeight;
    var lastDocumentHeight = $(document).height();
    var ticking = false;

    function onScroll() {
        lastScrollY = window.scrollY;
        requestTick();
    }

    function onResize() {
        lastWindowHeight = window.innerHeight;
        lastDocumentHeight = $(document).height();
        requestTick();
    }

    function requestTick() {
        if (!ticking) {
            requestAnimationFrame(update);
        }
        ticking = true;
    }

    function update() {
        var trigger = title.getBoundingClientRect().top + window.scrollY;
        var triggerOffset = title.offsetHeight + 35;
        var progressMax = lastDocumentHeight - lastWindowHeight;

        // show/hide floating header
        if (lastScrollY >= trigger + triggerOffset) {
            header.classList.add('floating-active');
        } else {
            header.classList.remove('floating-active');
        }

        progressBar.setAttribute('max', progressMax);
        progressBar.setAttribute('value', lastScrollY);

        ticking = false;
    }

    window.addEventListener('scroll', onScroll, {passive: true});
    window.addEventListener('resize', onResize, false);

    update();
});
</script>

    

    <!-- Ghost outputs important scripts and data with this tag - it should always be the very last thing before the closing body tag -->
    <!-- ghost_foot -->

</body>
</html>

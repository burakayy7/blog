<!DOCTYPE html>
<html>
<head>

    <!-- Document Settings -->
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />

    <!-- Base Meta -->
    <!-- dynamically fixing the title for tag/author pages -->



    <title>Gradient Descent & Linear Regression</title>
    <meta name="HandheldFriendly" content="True" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <!-- Styles'n'Scripts -->
    <link rel="stylesheet" type="text/css" href="/blog/assets/built/screen.css" />
    <link rel="stylesheet" type="text/css" href="/blog/assets/built/screen.edited.css" />
    <link rel="stylesheet" type="text/css" href="/blog/assets/built/syntax.css" />
    <!-- highlight.js -->
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css">
    <style>.hljs { background: none; }</style>

    <!--[if IE]>
        <style>
            p, ol, ul{
                width: 100%;
            }
            blockquote{
                width: 100%;
            }
        </style>
    <![endif]-->
    
    <!-- This tag outputs SEO meta+structured data and other important settings -->
    <meta name="description" content="My Blog for Technical Projects" />
    <link rel="shortcut icon" href="https://burakayy.com/blog/assets/images/favicon.png" type="image/png" />
    <link rel="canonical" href="https://burakayy.com/blog/Gradient-Descent" />
    <meta name="referrer" content="no-referrer-when-downgrade" />

     <!--title below is coming from _includes/dynamic_title-->
    <meta property="og:site_name" content="Burak Ayyorgun" />
    <meta property="og:type" content="website" />
    <meta property="og:title" content="Gradient Descent & Linear Regression" />
    <meta property="og:description" content="In this post I will be introducing the math behind Gradient Descent and how it works! I was first introduced to Gradient Descent when I had to implement autoregressive models from scratch. To learn this, I first tried to implement a Linear Regression. Disclaimer: I will be using Python code" />
    <meta property="og:url" content="https://burakayy.com/blog/Gradient-Descent" />
    <meta property="og:image" content="https://burakayy.com/blog/assets/images/Gradient/gdMain.png" />
    <meta property="article:publisher" content="https://www.facebook.com/ghost" />
    <meta property="article:author" content="https://www.facebook.com/ghost" />
    <meta property="article:published_time" content="2024-02-05T00:00:00+00:00" />
    <meta property="article:modified_time" content="2024-02-05T00:00:00+00:00" />
    <meta property="article:tag" content="Arima" />
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="Gradient Descent & Linear Regression" />
    <meta name="twitter:description" content="In this post I will be introducing the math behind Gradient Descent and how it works! I was first introduced to Gradient Descent when I had to implement autoregressive models from scratch. To learn this, I first tried to implement a Linear Regression. Disclaimer: I will be using Python code" />
    <meta name="twitter:url" content="https://burakayy.com/blog/" />
    <meta name="twitter:image" content="https://burakayy.com/blog/assets/images/Gradient/gdMain.png" />
    <meta name="twitter:label1" content="Written by" />
    <meta name="twitter:data1" content="Burak Ayyorgun" />
    <meta name="twitter:label2" content="Filed under" />
    <meta name="twitter:data2" content="Arima" />
    <meta name="twitter:site" content="@JoeBA07" />
    <meta name="twitter:creator" content="@JoeBA07" />
    <meta property="og:image:width" content="1400" />
    <meta property="og:image:height" content="933" />

    <script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Website",
    "publisher": {
        "@type": "Organization",
        "name": "Burak Ayyorgun",
        "logo": "https://burakayy.com/blog/Burak Ayyorgun"
    },
    "url": "https://burakayy.com/blog/Gradient-Descent",
    "image": {
        "@type": "ImageObject",
        "url": "https://burakayy.com/blog/assets/images/Gradient/gdMain.png",
        "width": 2000,
        "height": 666
    },
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "https://burakayy.com/blog/Gradient-Descent"
    },
    "description": "In this post I will be introducing the math behind Gradient Descent and how it works! I was first introduced to Gradient Descent when I had to implement autoregressive models from scratch. To learn this, I first tried to implement a Linear Regression. Disclaimer: I will be using Python code"
}
    </script>

    <!-- <script type="text/javascript" src="https://demo.ghost.io/public/ghost-sdk.min.js?v=724281a32e"></script>
    <script type="text/javascript">
    ghost.init({
    	clientId: "ghost-frontend",
    	clientSecret: "f84a07a72b17"
    });
    </script> -->

    <meta name="generator" content="Jekyll 3.6.2" />
    <link rel="alternate" type="application/rss+xml" title="Gradient Descent & Linear Regression" href="/blog/feed.xml" />


</head>
<body class="post-template">

    <div class="site-wrapper">
        <!-- All the main content gets inserted here, index.hbs, post.hbs, etc -->
        <!-- default -->
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
<!-- The tag above means: insert everything in this file
into the {body} of the default.hbs template -->

<header class="site-header outer">
    <div class="inner">
        
<nav class="site-nav">
    <div class="site-nav-left">
        
            
                <!-- <a class="site-nav-logo" href="https://burakayy.com/blog/"><img src="/blog/Burak Ayyorgun" alt="Burak Ayyorgun" /></a> -->
            <!-- <a class="site-nav-logo" href="https://burakayy.com/blog/">Home</a> -->
            
        
        
            <ul class="nav" role="menu">
    <li class="nav-home" role="menuitem" style="font-size: 20px; opacity: 0.99;"><a href="/blog/">Home</a></li>
    <li class="nav-about" role="menuitem" style="font-size: 20px; opacity: 0.99;"><a href="/blog/about/">About</a></li>
    <li class="nav-about" role="menuitem" style="font-size: 20px; opacity: 0.99;"><a href="/blog/courses">Courses</a></li>
    <!-- <li class="nav-getting-started" role="menuitem"><a href="/blog/tag/getting-started/">Getting Started</a></li> -->
    <!-- <li class="nav-try-ghost" role="menuitem"><a href="https://ghost.org">Try Ghost</a></li> -->
</ul>

        
    </div>
    <div class="site-nav-right">
        <!-- New navigation link -->
        <ul class="nav" role="menu">
            <li class="nav-home" role="menuitem" style="font-size: 20px; opacity: 1;"><a href="/blog/miscellaneous">Old Miscellaneous Projects</a></li>
        </ul>


        <!-- Social media links -->
        <div class="social-links">
            
                <a class="social-link social-link-fb" href="https://facebook.com/ghost" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path d="M19 6h5V0h-5c-3.86 0-7 3.14-7 7v3H8v6h4v16h6V16h5l1-6h-6V7c0-.542.458-1 1-1z"/></svg>
</a>
            
            
                <a class="social-link social-link-tw" href="https://twitter.com/JoeBA07" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path d="M30.063 7.313c-.813 1.125-1.75 2.125-2.875 2.938v.75c0 1.563-.188 3.125-.688 4.625a15.088 15.088 0 0 1-2.063 4.438c-.875 1.438-2 2.688-3.25 3.813a15.015 15.015 0 0 1-4.625 2.563c-1.813.688-3.75 1-5.75 1-3.25 0-6.188-.875-8.875-2.625.438.063.875.125 1.375.125 2.688 0 5.063-.875 7.188-2.5-1.25 0-2.375-.375-3.375-1.125s-1.688-1.688-2.063-2.875c.438.063.813.125 1.125.125.5 0 1-.063 1.5-.25-1.313-.25-2.438-.938-3.313-1.938a5.673 5.673 0 0 1-1.313-3.688v-.063c.813.438 1.688.688 2.625.688a5.228 5.228 0 0 1-1.875-2c-.5-.875-.688-1.813-.688-2.75 0-1.063.25-2.063.75-2.938 1.438 1.75 3.188 3.188 5.25 4.25s4.313 1.688 6.688 1.813a5.579 5.579 0 0 1 1.5-5.438c1.125-1.125 2.5-1.688 4.125-1.688s3.063.625 4.188 1.813a11.48 11.48 0 0 0 3.688-1.375c-.438 1.375-1.313 2.438-2.563 3.188 1.125-.125 2.188-.438 3.313-.875z"/></svg>
</a>
            
        </div>
        
            <a class="subscribe-button" href="#subscribe">Subscribe</a>
        
    </div>
</nav>

    </div>
</header>

<!-- Everything inside the #post tags pulls data from the post -->
<!-- #post -->

<main id="site-main" class="site-main outer" role="main">
    <div class="inner">

        <article class="post-full  tag-arima post ">

            <header class="post-full-header">
                <section class="post-full-meta">
                    <time class="post-full-meta-date" datetime=" 5 February 2024"> 5 February 2024</time>
                    
                        <span class="date-divider">/</span>
                        
                            
                               <a href='/blog/tag/arima/'>ARIMA</a>
                            
                        
                    
                </section>
                <h1 class="post-full-title">Gradient Descent & Linear Regression</h1>
            </header>

            
            <figure class="post-full-image" style="background-image: url(/blog/assets/images/Gradient/gdMain.png); height: 400px; background-size: cover; background-position: center;">
            </figure>
            

            <section class="post-full-content" style="margin-top: 60px;">
                <div class="kg-card-markdown">
                    <p>In this post I will be introducing the math behind Gradient Descent and how it works!</p>

<p>I was first introduced to Gradient Descent when I had to implement autoregressive models from scratch. To learn this, I first tried to implement a Linear Regression.</p>

<p><strong>Disclaimer: I will be using Python code in this tutorial found in my <a href="https://github.com/burakayy7/LinearRegression">repo</a>.</strong></p>

<p>Please follow along, I think it helps to see an example. Or better yet, create your own script by using the code in this post.</p>

<p>Linear Regressions are brought up in the context of tring to find a line that best fits the trend of a data set.
For example, lets say we wanted to find the line which best represents this graph:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="o">-</span><span class="mi">110</span><span class="p">,</span> <span class="mi">120</span><span class="p">,</span> <span class="mi">10</span><span class="p">)]</span>
<span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="o">*</span><span class="n">i</span><span class="o">-</span><span class="mi">5</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">x</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="p">(</span><span class="n">random</span><span class="p">.</span><span class="n">random</span><span class="p">()</span><span class="o">*</span><span class="mi">250</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">y</span><span class="p">]</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s">'a1'</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span> <span class="s">'a2'</span><span class="p">:</span> <span class="n">y</span><span class="p">})</span>
<span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">a1</span><span class="p">,</span> <span class="n">df</span><span class="p">.</span><span class="n">a2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">"black"</span><span class="p">)</span>
</code></pre></div></div>
<p><img src="assets/images/AutoCorr/graph2.png" alt="image" /></p>

<p>Well, we know that the final equation will look something like this:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>y = mx + b
</code></pre></div></div>
<p>So all we have to do is find the appropriate values for m and b. While we could go the trial-and-error method and try a bunch of values until the result <em>looks right</em>, we could also have a computer automate that process for us.</p>

<h3 id="here-is-how-the-linear-regression-algorithm-works">Here is how the Linear Regression Algorithm works:</h3>
<ol>
  <li>Start with an initial line equation</li>
  <li>Calculate how far you are from the expected value when you plug in a point, using the current m and b.</li>
  <li>Then slightly adjust m and b in the <em>direction</em> which will get us <em>closer</em> to the expected value</li>
  <li>Repeat steps 2 and 3 for a specified amount (this is referred to as the epoch size)</li>
</ol>

<p>First, start off with a random set of m (this is often referred to as the weight because is has a scaling affect) and b (which is referred to as the bias because it will shift, or apply a bias, to our line). For simplisity sake, we can also start off with m and b equaling zero.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">m</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">b</span> <span class="o">=</span> <span class="mi">0</span>
</code></pre></div></div>
<p>Then we take our first point in the data set and plug it into our line equation. This should give us an output value. We can compare this with the expected value (since we know the point) by finding the error. Now, there are a variety of different error functions (referred to as the cost function, can you see why?) which can be used, and it will depend on your system. But for simplicity sake, I have chosen the <em>Mean Squared Error</em> cost function.</p>

<h4 id="how-does-the-mean-squared-error-cost-function-work">How does the Mean Squared Error Cost Function Work</h4>

<p>So imagine we know the real value, say y_real. Then from some equation we get a computed value, say y_cal. We wish to know the error between these. The first thing that comes to mind is simply</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>error = y_real - y_cal
</code></pre></div></div>
<p>However, what if over time we got a bunch of negative and positive error values that when summed up (which will happen in our MeanSquaredError function because we will calculate the error across the entire dataset at once) would result in a value close to zero (the positive and negaitves would cancel)? This is where the <em>squared</em> term comes in. By squaring the error value, we eliminate the posability of a negative value.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">error</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_real</span> <span class="o">-</span> <span class="n">y_cal</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>
</code></pre></div></div>
<p>Next, we wish to know the error across the entire dataset, so the somewhat obvious method might be to take the average of all the errors between every point, this is the <em>mean</em> term.</p>

<p>So now our algorithm is something like this:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">mean_squared_error</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">points</span><span class="p">):</span>
  <span class="n">total_error</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">points</span><span class="p">)):</span>
    <span class="n">x_i</span> <span class="o">=</span> <span class="n">points</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">a1</span>
    <span class="n">y_i</span> <span class="o">=</span> <span class="n">points</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">a2</span>
    <span class="n">total_error</span> <span class="o">+=</span> <span class="p">(</span><span class="n">y_i</span> <span class="o">-</span> <span class="p">(</span><span class="n">m</span><span class="o">*</span><span class="n">x_i</span><span class="o">+</span><span class="n">b</span><span class="p">))</span><span class="o">**</span><span class="mi">2</span>
  <span class="k">return</span> <span class="n">total_error</span><span class="o">/</span><span class="nb">float</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">points</span><span class="p">))</span> <span class="c1">#take the average
</span></code></pre></div></div>
<p>Here <em>points</em> is a <a href="https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html">Pandas DataFrame</a> and I just access the x and y components. And when calculating the error, I just simply calculate the value on the spot with <code class="language-plaintext highlighter-rouge">total_error += (y_i - (m*x_i+b))**2</code> ,adding it to a variable to then take the average.</p>

<p>Easy enough? If not, here is another resource: <a href="https://statisticsbyjim.com/regression/mean-squared-error-mse/">for help</a></p>

<p>Once we know our error, we wish to know how much we should adjust m and b according to this value. If we have a big error, maybe we should make a big change, but if it’s small, a tiny change might be sufficient.</p>

<p>This is when Gradient Descent comes in.</p>

<p>The underlining goal in the Linear Regression algorithm is to modify the weights and biases in such a way, that we get closer to our goal. But the question remains: How do we know how much we want to modify each value?</p>

<h3 id="how-does-gradient-descent-work">How does Gradient Descent Work</h3>

<p>So let’s observe our cost function:</p>

\[\text{error} = \sum_{i=0}^n (y_i - (m \cdot x_i + b))^2\]

<p>The first thing we wish to know, is how much our error will change with a small change in m. Then according to that value, we will adjust m to reduce our error. We then repeat this process for b.</p>

<p>And this is when something called <a href="https://en.wikipedia.org/wiki/Derivative">Derivative</a> comes in.</p>

<p><em>Now I wish I could go into great detail on how a derivative works and the theory behind it, but this post is already getting wordy, so reach out and let me know if you would like a seperate post on derivatives.</em></p>

<p>So essentially, what we are doing with the partial derivatives, is we are trying to calculate the slope of our cost function at a given point with respect to one of the variables, like either m or b (this is actually close to the definition of a partial derivative. We simply wish to know the effect a variable will have on the output).</p>

<p>And to do this (again, I won’t be going in-depth on partial derivatives in this tutorial) we are going to treat every variable other than the one we are interested in as a constant.</p>

\[\frac{\partial \text{error}}{\partial m} = \lim_{h \to 0} \frac{f(x + h) - f(x)}{h}\]

<p>and</p>

\[\frac{\partial \text{error}}{\partial b} = \lim_{h \to 0} \frac{f(x + h) - f(x)}{h}\]

<p>(notice how these are very similar to slope equations, can you see why?)</p>

<p>which becomes</p>

\[\frac{\partial \text{error}}{\partial m} = \lim_{h \to 0} \frac{\sum_{i=0}^n \left(y_i - \left((m + h) \cdot x_i + b\right)\right)^2 - \sum_{i=0}^n \left(y_i - (m \cdot x_i + b)\right)^2}{h}\]

<p>and</p>

\[\frac{\partial \text{error}}{\partial b} = \lim_{h \to 0} \frac{(\sum_{i=0}^n (y_i - (m \cdot x_i + (b+h)))^2) - (\sum_{i=0}^n (y_i - (m \cdot x_i + b))^2)}{h}\]

<p>And once we do the algebra (which I highly suggest you do by hand to really understand), we are left with these two equations:</p>

\[\frac{\partial \text{error}}{\partial m} = -\frac{2}{n} \cdot \sum_{i=0}^n (y_i \cdot x_i - x_i^2 \cdot m + x_i \cdot b)\]

<p>and</p>

\[\frac{\partial \text{error}}{\partial b} = -\frac{2}{n} \cdot \sum_{i=0}^n (y_i - m \cdot x_i - b)\]

<p>Voila!</p>

<p>Now we know the effect m and b will have on our error. And all we have to do is adjust m and b in such a way that we will have reduced our error.</p>

<p>Now for simplisicty sake, I want you to imagine this: let’s say we graphed our cost function and we found the slope of the tangent line at a given point (our derivative). We can find the lowest point (or the lowest our cost function is) if we move <u>away</u> from the <em>steepness</em> or the slope.</p>

<p>So here is a super quick sketch:</p>

<p><img src="assets/images/Gradient/gd.png" alt="" /></p>

<p>Now all we have to do is adjust m and b in the opposite direction of the steepness, which we do by subtracting our gradient times some <em>learning rate</em>. All the learning rate does, is it scales the amount which we will adjust m and b to a much smaller value so we don’t make big jumps; we make small, incremental, adjustments. But this is just another parameter you can adjust for your problem.</p>

\[\text{m} = \text{m} - \alpha \cdot \frac{\partial \text{error}}{\partial m}\]

\[\text{b} = \text{b} - \alpha \cdot \frac{\partial \text{error}}{\partial b}\]

<p>Here, $\alpha$  is my learning rate, and in the code below, it’s set to 0.0001</p>

<p>So here is my Python function for doing this Gradient Descent:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">gradient_descent</span><span class="p">(</span><span class="n">m_now</span><span class="p">,</span> <span class="n">b_now</span><span class="p">,</span> <span class="n">points</span><span class="p">,</span> <span class="n">L</span><span class="p">):</span>
  <span class="n">m_gradient</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">b_gradient</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">points</span><span class="p">)</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="n">x_i</span> <span class="o">=</span> <span class="n">points</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">a1</span>
    <span class="n">y_i</span> <span class="o">=</span> <span class="n">points</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">a2</span>
    <span class="n">m_gradient</span> <span class="o">+=</span> <span class="o">-</span><span class="p">(</span><span class="mi">2</span><span class="o">/</span><span class="n">n</span><span class="p">)</span> <span class="o">*</span><span class="n">x_i</span><span class="o">*</span><span class="p">(</span><span class="n">y_i</span><span class="o">-</span><span class="p">(</span><span class="n">m_now</span><span class="o">*</span><span class="n">x_i</span><span class="o">+</span><span class="n">b_now</span><span class="p">))</span>
    <span class="n">b_gradient</span> <span class="o">+=</span> <span class="o">-</span><span class="p">(</span><span class="mi">2</span><span class="o">/</span><span class="n">n</span><span class="p">)</span> <span class="o">*</span><span class="p">(</span><span class="n">y_i</span><span class="o">-</span><span class="p">(</span><span class="n">m_now</span><span class="o">*</span><span class="n">x_i</span><span class="o">+</span><span class="n">b_now</span><span class="p">))</span>
  <span class="n">m</span> <span class="o">=</span> <span class="n">m_now</span> <span class="o">-</span> <span class="n">m_gradient</span> <span class="o">*</span> <span class="n">L</span>
  <span class="n">b</span> <span class="o">=</span> <span class="n">b_now</span> <span class="o">-</span> <span class="n">b_gradient</span> <span class="o">*</span> <span class="n">L</span>
  <span class="k">return</span> <span class="n">m</span><span class="p">,</span> <span class="n">b</span>
</code></pre></div></div>

<p>and this is the code where the Linear Regression and Gradient Descent happens:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">m</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">b</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">L</span> <span class="o">=</span> <span class="mf">0.0001</span>
<span class="n">epoch</span> <span class="o">=</span> <span class="mi">200</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epoch</span><span class="p">):</span>
  <span class="n">m</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">gradient_descent</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">L</span><span class="p">)</span>
</code></pre></div></div>
<p>Here, I set the epochs (which is how many times we update m and b) to 200. You can play around with these values (epoch and L), they are the hyperparameters.</p>

<p>In each epoch, we update m and b, and re-run our algorithm; each time getting closer and closer to the actual m and b values.</p>

<p>If you went to the <a href="https://github.com/burakayy7/LinearRegression">repo</a> and ran the cell, you should see something like this:</p>

<p><img src="assets\images\Gradient\gd1.png" alt="" /></p>

<p>And if you print out the m and b values, you should get something close to</p>

<p>\(\text{m} = 3.074\)
\(\text{b} = 4.314\)</p>

<p>Which is really close to our actual m and b, which was defined as m = 3 and b = 5.</p>

<h2 id="where-is-linear-regression-useful">Where is Linear Regression Useful</h2>

<p>Well, Linear Regression is actually the simpliest Machine Learning model. We created an algorithm that <em>learns</em> a set of variables. This fundamental idea is used in Neural Networks. In fact, each neuron in the network behaves similar to a Linear Regression. Each neuron learns a set of weights and biases, similar to how we learned a set of m and b.</p>

<p>I hope you learned something, and don’t be afraid to reach out with suggestions and questions!!</p>

<p>See you next time!</p>

                </div>
            </section>

            <!-- Email subscribe form at the bottom of the page -->
            
                <section class="subscribe-form">
                    <h3 class="subscribe-form-title">Subscribe to Burak Ayyorgun</h3>
                    <p>Get the latest posts delivered right to your inbox</p>
                    <form method="post" action="/subscribe/" class="">
    <input class="confirm" type="hidden" name="confirm"  /><input class="location" type="hidden" name="location"  /><input class="referrer" type="hidden" name="referrer"  />

    <div class="form-group">
        <input class="subscribe-email" type="email" name="email"  placeholder="youremail@example.com" />
    </div>
    <button class="" type="submit" disabled><span>Subscribe</span></button>
    <script type="text/javascript">(function(g,h,o,s,t){h[o]('.location')[s]=h[o]('.location')[s] || g.location.href;h[o]('.referrer')[s]=h[o]('.referrer')[s] || h.referrer;})(window,document,'querySelector','value');</script>
</form>

                </section>
            

            <footer class="post-full-footer">
                <!-- Everything inside the #author tags pulls data from the author -->
                <!-- #author-->
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                <!-- /author  -->
            </footer>

            <!-- If you use Disqus comments, just uncomment this block.
            The only thing you need to change is "test-apkdzgmqhj" - which
            should be replaced with your own Disqus site-id. -->
            

        </article>

    </div>
</main>

<!-- Links to Previous/Next posts -->
<aside class="read-next outer">
    <div class="inner">
        <div class="read-next-feed">
            
                
                
                
                
                    <article class="read-next-card"
                        
                            style="background-image: url(/blog/assets/images/planeBkg.jpg)"
                        
                    >
                        <header class="read-next-card-header">
                            <small class="read-next-card-header-sitetitle">&mdash; Burak Ayyorgun &mdash;</small>
                            
                                <h3 class="read-next-card-header-title"><a href="/blog/tag/arima/">Arima</a></h3>
                            
                        </header>
                        <div class="read-next-divider"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 14.5s2 3 5 3 5.5-2.463 5.5-5.5S21 6.5 18 6.5c-5 0-7 11-12 11C2.962 17.5.5 15.037.5 12S3 6.5 6 6.5s4.5 3.5 4.5 3.5"/></svg>
</div>
                        <div class="read-next-card-content">
                            <ul>
                                
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                    
                                        
                                        
                                            <li><a href="/blog/arima-future">Future Works & Next Steps</a></li>
                                        
                                    
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                    
                                        
                                        
                                            <li><a href="/blog/how-arima-works">Part 2 - Implementing a Full ARIMA model from SCRATCH!</a></li>
                                        
                                    
                                  
                                
                                  
                                    
                                        
                                        
                                            <li><a href="/blog/arima-work">Part 1 - What are ARIMA models and how do they work?</a></li>
                                        
                                    
                                  
                                
                                  
                                    
                                        
                                        
                                    
                                  
                                
                                  
                                    
                                        
                                        
                                    
                                  
                                
                                  
                                    
                                  
                                
                                  
                                    
                                        
                                        
                                    
                                  
                                
                                  
                                    
                                        
                                        
                                    
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                            </ul>
                        </div>
                        <footer class="read-next-card-footer">
                            <a href="/blog/tag/arima/">
                                
                                    See all 7 posts  →
                                
                            </a>
                        </footer>
                    </article>
                
            

            <!-- If there's a next post, display it using the same markup included from - partials/post-card.hbs -->
            
                

    <article class="post-card post-template">
        
            <a class="post-card-image-link" href="/blog/stationary-data">
                <div class="post-card-image" style="background-image: url(/blog/assets/images/AutoCorr/stationary.png)"></div>
            </a>
        
        <div class="post-card-content">
            <a class="post-card-content-link" href="/blog/stationary-data">
                <header class="post-card-header">
                    
                        
                            
                                <span class="post-card-tags">Arima</span>
                            
                        
                    

                    <h2 class="post-card-title">What is Stationary Data & Unit Root Tests</h2>
                </header>
                <section class="post-card-excerpt">
                    
                        <p>To prepare for the next lesson, I wanted to provide a quick lesson explaining what stationary data is. What is Stationarity By textbook definition, a stationary time series (a dataset which is a</p>
                    
                </section>
            </a>
            <footer class="post-card-meta">
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                <span class="reading-time">
                    
                    
                      6 min read
                    
                </span>
            </footer>
        </div>
    </article>

            

            <!-- If there's a previous post, display it using the same markup included from - partials/post-card.hbs -->
            
                

    <article class="post-card post-template">
        
            <a class="post-card-image-link" href="/blog/Autocorrelation,-Moving-Average,&-More">
                <div class="post-card-image" style="background-image: url(/blog/assets/images/AutoCorr/ACmain.png)"></div>
            </a>
        
        <div class="post-card-content">
            <a class="post-card-content-link" href="/blog/Autocorrelation,-Moving-Average,&-More">
                <header class="post-card-header">
                    
                        
                            
                                <span class="post-card-tags">Arima</span>
                            
                        
                    

                    <h2 class="post-card-title">Part 2 - Autocorrelation, Moving Average, & More</h2>
                </header>
                <section class="post-card-excerpt">
                    
                        <p>A simple introduction to Seasonal Trends, Decompositions, and many more! This is the second and last part of the lessons on Autocorrelation, Moving Averages, Trends, and Decompositions. For the code used in this</p>
                    
                </section>
            </a>
            <footer class="post-card-meta">
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                <span class="reading-time">
                    
                    
                      7 min read
                    
                </span>
            </footer>
        </div>
    </article>

            

        </div>
    </div>
</aside>

<!-- Floating header which appears on-scroll, included from includes/floating-header.hbs -->
<div class="floating-header">
    <div class="floating-header-logo">
        <a href="https://burakayy.com/blog/">
            
                <img src="/blog/assets/images/favicon.png" alt="Burak Ayyorgun icon" />
            
            <span>Burak Ayyorgun</span>
        </a>
    </div>
    <span class="floating-header-divider">&mdash;</span>
    <div class="floating-header-title">
        Gradient Descent & Linear Regression
    <span></span></div>
    
    <div class="floating-header-share">
        <div class="floating-header-share-label">Share this <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
    <path d="M7.5 15.5V4a1.5 1.5 0 1 1 3 0v4.5h2a1 1 0 0 1 1 1h2a1 1 0 0 1 1 1H18a1.5 1.5 0 0 1 1.5 1.5v3.099c0 .929-.13 1.854-.385 2.748L17.5 23.5h-9c-1.5-2-5.417-8.673-5.417-8.673a1.2 1.2 0 0 1 1.76-1.605L7.5 15.5zm6-6v2m-3-3.5v3.5m6-1v2"/>
</svg>
</div>
        <a class="floating-header-share-tw" href="https://twitter.com/share?text=Gradient+Descent+%26+Linear+Regression&amp;url=https://burakayy.com/blog/Gradient-Descent"
            onclick="window.open(this.href, 'share-twitter', 'width=550,height=235');return false;">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path d="M30.063 7.313c-.813 1.125-1.75 2.125-2.875 2.938v.75c0 1.563-.188 3.125-.688 4.625a15.088 15.088 0 0 1-2.063 4.438c-.875 1.438-2 2.688-3.25 3.813a15.015 15.015 0 0 1-4.625 2.563c-1.813.688-3.75 1-5.75 1-3.25 0-6.188-.875-8.875-2.625.438.063.875.125 1.375.125 2.688 0 5.063-.875 7.188-2.5-1.25 0-2.375-.375-3.375-1.125s-1.688-1.688-2.063-2.875c.438.063.813.125 1.125.125.5 0 1-.063 1.5-.25-1.313-.25-2.438-.938-3.313-1.938a5.673 5.673 0 0 1-1.313-3.688v-.063c.813.438 1.688.688 2.625.688a5.228 5.228 0 0 1-1.875-2c-.5-.875-.688-1.813-.688-2.75 0-1.063.25-2.063.75-2.938 1.438 1.75 3.188 3.188 5.25 4.25s4.313 1.688 6.688 1.813a5.579 5.579 0 0 1 1.5-5.438c1.125-1.125 2.5-1.688 4.125-1.688s3.063.625 4.188 1.813a11.48 11.48 0 0 0 3.688-1.375c-.438 1.375-1.313 2.438-2.563 3.188 1.125-.125 2.188-.438 3.313-.875z"/></svg>

        </a>
        <a class="floating-header-share-fb" href="https://www.facebook.com/sharer/sharer.php?u=https://burakayy.com/blog/Gradient-Descent"
            onclick="window.open(this.href, 'share-facebook','width=580,height=296');return false;">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path d="M19 6h5V0h-5c-3.86 0-7 3.14-7 7v3H8v6h4v16h6V16h5l1-6h-6V7c0-.542.458-1 1-1z"/></svg>

        </a>
    </div>
    <progress class="progress" value="0">
        <div class="progress-container">
            <span class="progress-bar"></span>
        </div>
    </progress>
</div>


<!-- /post -->

<!-- The #contentFor helper here will send everything inside it up to the matching #block helper found in default.hbs -->







        <!-- Previous/next page links - displayed on every page -->
        

        <!-- The footer at the very bottom of the screen -->
        <footer class="site-footer outer">
            <div class="site-footer-content inner">
                <section class="copyright"><a href="https://burakayy.com/blog/">Burak Ayyorgun</a> &copy; 2026</section>
                <!-- <section class="poweredby">Proudly published with <a href="https://jekyllrb.com/">Jekyll</a> &
                    <a href="https://pages.github.com/" target="_blank" rel="noopener">GitHub Pages</a> using
                    <a href="https://github.com/jekyllt/jasper2" target="_blank" rel="noopener">Jasper2</a></section> -->
                <nav class="site-footer-nav">
                    <a href="/blog/">Latest Posts</a>
                    <a href="https://facebook.com/ghost" target="_blank" rel="noopener">Facebook</a>
                    <a href="https://twitter.com/JoeBA07" target="_blank" rel="noopener">Twitter</a>
                    <a href="https://ghost.org" target="_blank" rel="noopener">Ghost</a>
                </nav>
            </div>
        </footer>

    </div>

    <!-- The big email subscribe modal content -->
    
        <div id="subscribe" class="subscribe-overlay">
            <a class="subscribe-overlay-close" href="#"></a>
            <div class="subscribe-overlay-content">
                
                    <img class="subscribe-overlay-logo" src="/blog/Burak Ayyorgun" alt="Burak Ayyorgun" />
                
                <h1 class="subscribe-overlay-title">Subscribe to Burak Ayyorgun</h1>
                <p class="subscribe-overlay-description">Stay up to date! Get all the latest &amp; greatest posts delivered straight to your inbox</p>
                <form method="post" action="/subscribe/" class="">
    <input class="confirm" type="hidden" name="confirm"  /><input class="location" type="hidden" name="location"  /><input class="referrer" type="hidden" name="referrer"  />

    <div class="form-group">
        <input class="subscribe-email" type="email" name="email"  placeholder="youremail@example.com" />
    </div>
    <button class="" type="submit" disabled><span>Subscribe</span></button>
    <script type="text/javascript">(function(g,h,o,s,t){h[o]('.location')[s]=h[o]('.location')[s] || g.location.href;h[o]('.referrer')[s]=h[o]('.referrer')[s] || h.referrer;})(window,document,'querySelector','value');</script>
</form>

            </div>
        </div>
    

    <!-- highlight.js -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.10.0/components/prism-abap.min.js"></script>
    <script>$(document).ready(function() {
      $('pre code').each(function(i, block) {
        hljs.highlightBlock(block);
      });
    });</script>

    <!-- Load the core Prism.js library -->
<!--     <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.10.0/prism.min.js"></script>
    
    <!-- Load the ABAP language component for Prism.js -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.10.0/components/prism-abap.min.js"></script>
    
    <!-- Initialize Prism.js (no need for extra jQuery or highlight.js) -->
    <script>$(document).ready(function() {
      $('pre code').each(function(i, block) {
        hljs.highlightBlock(block);
      });
    });</script>
    <script>
      document.addEventListener('DOMContentLoaded', (event) => {
        // Prism.js will automatically highlight all <code> blocks on the page
      });
    </script> -->


    <!-- jQuery + Fitvids, which makes all video embeds responsive -->
    <script
        src="https://code.jquery.com/jquery-3.2.1.min.js"
        integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4="
        crossorigin="anonymous">
    </script>
    <script type="text/javascript" src="/blog/assets/js/jquery.fitvids.js"></script>
    <script type="text/javascript" src="https://demo.ghost.io/assets/js/jquery.fitvids.js?v=724281a32e"></script>


    <!-- Paginator increased to "infinit" in _config.yml -->
    <!-- if paginator.posts  -->
    <!-- <script>
        var maxPages = parseInt('');
    </script>
    <script src="/blog/assets/js/infinitescroll.js"></script> -->
    <!-- /endif -->

    


    <!-- Add Google Analytics  -->
    <!-- Google Analytics Tracking code -->
 <!-- <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'G-MY3WXBS5JD', 'auto');
  ga('send', 'pageview');

 </script> -->

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-MY3WXBS5JD"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-MY3WXBS5JD');
</script>


    <!-- The #block helper will pull in data from the #contentFor other template files. In this case, there's some JavaScript which we only want to use in post.hbs, but it needs to be included down here, after jQuery has already loaded. -->
    
        <script>

// NOTE: Scroll performance is poor in Safari
// - this appears to be due to the events firing much more slowly in Safari.
//   Dropping the scroll event and using only a raf loop results in smoother
//   scrolling but continuous processing even when not scrolling
$(document).ready(function () {
    // Start fitVids
    var $postContent = $(".post-full-content");
    $postContent.fitVids();
    // End fitVids

    var progressBar = document.querySelector('progress');
    var header = document.querySelector('.floating-header');
    var title = document.querySelector('.post-full-title');

    var lastScrollY = window.scrollY;
    var lastWindowHeight = window.innerHeight;
    var lastDocumentHeight = $(document).height();
    var ticking = false;

    function onScroll() {
        lastScrollY = window.scrollY;
        requestTick();
    }

    function onResize() {
        lastWindowHeight = window.innerHeight;
        lastDocumentHeight = $(document).height();
        requestTick();
    }

    function requestTick() {
        if (!ticking) {
            requestAnimationFrame(update);
        }
        ticking = true;
    }

    function update() {
        var trigger = title.getBoundingClientRect().top + window.scrollY;
        var triggerOffset = title.offsetHeight + 35;
        var progressMax = lastDocumentHeight - lastWindowHeight;

        // show/hide floating header
        if (lastScrollY >= trigger + triggerOffset) {
            header.classList.add('floating-active');
        } else {
            header.classList.remove('floating-active');
        }

        progressBar.setAttribute('max', progressMax);
        progressBar.setAttribute('value', lastScrollY);

        ticking = false;
    }

    window.addEventListener('scroll', onScroll, {passive: true});
    window.addEventListener('resize', onResize, false);

    update();
});
</script>

    

    <!-- Ghost outputs important scripts and data with this tag - it should always be the very last thing before the closing body tag -->
    <!-- ghost_foot -->

</body>
</html>
